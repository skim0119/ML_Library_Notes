{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상수, 변수, 플레이스홀더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상수\n",
    "\n",
    "``` py\n",
    "tf.constant(\n",
    "    value,\n",
    "    dtype=None,\n",
    "    shape=None,\n",
    "    name='Const',\n",
    "    verify_shape=False\n",
    ")\n",
    "```\n",
    "\n",
    "텐서플로에서 상수는 고정값을 의미합니다. 값 자체는 행렬이거나 텐서여도 무관합니다.\n",
    "\n",
    "행렬이나 텐서를 상수값으로 넣을때는 주로 넘피(numpy) 데이터형을 사용하게 됩니다. 이때 shape을 굳이 넣지 않아도 텐서플로는 자연스럽게 np.shape 값을 shape 값으로 기록하게 됩니다.\n",
    "\n",
    "만약 shape값을 직접 지정해주었지만, value의 행렬크기가 더 클경우에는 오류를 반환합니다.\n",
    "반대로, 지정된 shape값보다 value 행렬 크기가 작을 경우, 남은 공간들을 value에 가장 마지막 값으로 복사해 넣게됩니다.\n",
    "verify_shape이 참(true)일 경우에는 shape값과 value의 행렬크기가 같지 않는 경우 모두 오류를 반환하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(3, 3), dtype=int32) \n",
      " [[1 4 3]\n",
      " [3 3 3]\n",
      " [3 3 3]]\n",
      "Tensor(\"y:0\", shape=(), dtype=int32) \n",
      " 5\n",
      "Tensor(\"Const:0\", shape=(2, 2), dtype=int32) \n",
      " [[1 3]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.constant([1,4,3], shape=(3,3), name='x')\n",
    "y = tf.constant(5, name='y')\n",
    "z = tf.constant([[1,3],[2,5]])\n",
    "\n",
    "sess = tf.Session()\n",
    "print(x, '\\n', sess.run(x))\n",
    "print(y, '\\n', sess.run(y))\n",
    "print(z, '\\n', sess.run(z))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플레이스홀더\n",
    "\n",
    "``` py\n",
    "tf.placeholder(\n",
    "    dtype,\n",
    "    shape=None,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "플레이스홀더는 계산중 입력값을 받는 변수입니다. 일반 변수와의 차이점은 플레이스홀더는 실행당시 직접 값을 넣어주어야 하지만 변수는 항상 어떠한 값을 가지고 있습니다.\n",
    "\n",
    "플레이스홀더를 지정할때 가장 필수적인 요소는 데이터형입니다. 데이터를 입력받을 때 어떤 데이터형으로 받을지를 미리 정해두는 것은 추후에 생길 계산에 형변환 오류를 방지하기 위해서입니다.\n",
    "\n",
    "플레이스홀더를 지정할때 사이즈에 None값을 사용할 수 있는데, None은 크기가 정해지지 않았다는 의미를 가지고 있습니다.\n",
    "\n",
    "이런 방법을 사용하는 이유는 대부분 머신러닝을 할때 주어진 데이터 양이 일정하지 않기때문입니다.\n",
    "\n",
    "대부분 플레이스홀더는 인풋(input)을 의미할때 사용하고, 사이즈는 대부분 [None, (input shape)] 을 사용합니다. 예를들어 인풋이 256x256 사이즈의 이미지일 경우 사이즈는 [None, 256, 256]을 사용합니다.\n",
    "\n",
    "그래프를 실행할 때 플레이스홀더에 값을 넣는 방법은 세션을 실행하는 메소드인 run 안에 딕셔너리 형으로 넣는 방법입니다.\n",
    "\n",
    "만약 입력된 데이터 값과 플레이스홀더의 shape이 맞지 않는 경우에는 오류를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, 2])\n",
    "x_data = [[1, 2], [3, 4], [5,6]]\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(x, feed_dict={x:x_data}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skim0119/Desktop/Project/ML_Library_Notes/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n",
      "=== x_data ===\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "=== W ===\n",
      "[[ 0.26188758 -1.2323303 ]\n",
      " [-0.47956774  0.1896324 ]\n",
      " [-0.6941297  -0.268216  ]]\n",
      "=== b ===\n",
      "[[0.23171921]\n",
      " [0.53967345]]\n",
      "=== expr ===\n",
      "[[-2.5479176 -1.4259943]\n",
      " [-4.9753933 -5.0507817]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
    "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)\n",
    "\n",
    "# X 플레이스홀더에 넣을 값 입니다.\n",
    "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
    "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
    "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
    "expr = tf.matmul(X, W) + b\n",
    "\n",
    "sess = tf.Session()\n",
    "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
    "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
    "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "\n",
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
